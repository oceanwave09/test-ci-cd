apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: delta-load-on-request-job-$RANDOM_ID
  namespace: data-pipeline
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: "registry.gitlab.com/health-ec/platform/domain/member/etl/patient-data-pipeline-jobs/patient-data-pipeline:latest"
  imagePullPolicy: Always
  imagePullSecrets:
    - gitlab-patient-datapipeline-regcred
  mainApplicationFile: local:///app/jobs/utility/delta_load_on_request_job.py
  deps:
    pyFiles:
      - local:///app/python-deps.zip
  sparkVersion: "3.4.1"
  timeToLiveSeconds: 3600
  nodeSelector:
    role: pyspark_jobs
  restartPolicy:
    type: Never
  driver:
    cores: 1
    memory: "4096m"
    labels:
      version: 3.4.1
      auto_scaling_groups: pyspark_jobs
    serviceAccount: spark-operator-spark
    env:
      - name: DELTA_SCHEMA_LOCATION
        valueFrom:
          configMapKeyRef:
            name: analytical-pipeline-config
            key: ${TENANT}.analytical_schema_location
      - name: DATA_FILE_PATH
        value: $DATA_FILE_PATH
      - name: FILE_TENANT
        value: $FILE_TENANT
      - name: DELTA_SCHEMA
        value: $DELTA_SCHEMA
      - name: DELTA_TABLE
        value: $DELTA_TABLE
      - name: DELIMITER
        value: "${DELIMITER}"
      - name: MODE
        value: $MODE
    tolerations:
      - key: dedicated
        operator: "Equal"
        value: pyspark_jobs
        effect: NoSchedule
  executor:
    cores: 1
    instances: 1
    memory: "4096m"
    labels:
      version: 3.4.1
      auto_scaling_groups: pyspark_jobs
    env:
      - name: DELTA_SCHEMA_LOCATION
        valueFrom:
          configMapKeyRef:
            name: analytical-pipeline-config
            key: ${TENANT}.analytical_schema_location
      - name: DATA_FILE_PATH
        value: $DATA_FILE_PATH
      - name: FILE_TENANT
        value: $FILE_TENANT
      - name: DELTA_SCHEMA
        value: $DELTA_SCHEMA
      - name: DELTA_TABLE
        value: $DELTA_TABLE
      - name: DELIMITER
        value: "${DELIMITER}"
      - name: MODE
        value: $MODE 
    tolerations:
      - key: dedicated
        operator: "Equal"
        value: pyspark_jobs
        effect: NoSchedule
